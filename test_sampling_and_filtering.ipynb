{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 25 PDF files and copied them to /data/users/brandon/ob1-projects/data_processing/indo_journals_sample\n"
     ]
    }
   ],
   "source": [
    "# randomy copy 500 pdfs from indo_journals to indo_journals_sample folder\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Define the source and destination directories\n",
    "source_dir = \"/data/users/brandon/ob1-projects/data_processing/indo_journals\"\n",
    "destination_dir = \"/data/users/brandon/ob1-projects/data_processing/indo_journals_sample\"\n",
    "\n",
    "# Create the destination directory if it doesn't exist\n",
    "os.makedirs(destination_dir, exist_ok=True)\n",
    "\n",
    "# Get a list of all PDF files in the source directory\n",
    "pdf_files = [f for f in os.listdir(source_dir) if f.endswith('.pdf')]\n",
    "\n",
    "# Randomly select 500 PDF files\n",
    "selected_pdfs = random.sample(pdf_files, 25)\n",
    "\n",
    "# Copy the selected PDF files to the destination directory\n",
    "for pdf in selected_pdfs:\n",
    "    shutil.copy(os.path.join(source_dir, pdf), os.path.join(destination_dir, pdf))\n",
    "\n",
    "print(f\"Selected {len(selected_pdfs)} PDF files and copied them to {destination_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            pdf_path  page_count  is_relevant  \\\n",
      "0  file:/data/users/brandon/ob1-projects/data_pro...           4         True   \n",
      "1  file:/data/users/brandon/ob1-projects/data_pro...           8         True   \n",
      "2  file:/data/users/brandon/ob1-projects/data_pro...          11        False   \n",
      "3  file:/data/users/brandon/ob1-projects/data_pro...          18        False   \n",
      "4  file:/data/users/brandon/ob1-projects/data_pro...           6         True   \n",
      "\n",
      "                                            ocr_text  \n",
      "0  Jurnal Teknik Komputer Unikom – Komputika – Vo...  \n",
      "1  Vol. 1. No. 2, 2015  Jurnal Teknik Industri Ju...  \n",
      "2   \\n \\nJurnal Porkes  Edisi J uni  |  272 \\nJur...  \n",
      "3   Center for Digital Innovation Studies (DIGITS...  \n",
      "4  JURNAL SAINS DAN SENI ITS Vol. 7, No. 2 (2018)...  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24 entries, 0 to 23\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   pdf_path     24 non-null     object\n",
      " 1   page_count   24 non-null     int64 \n",
      " 2   is_relevant  24 non-null     bool  \n",
      " 3   ocr_text     24 non-null     object\n",
      "dtypes: bool(1), int64(1), object(2)\n",
      "memory usage: 732.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv(\"/data/users/brandon/ob1-projects/data_processing/ocr_results.csv\")\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Display information about the DataFrame\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "print(len(df[\"pdf_path\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/users/brandon/ob1-projects/data_processing/indo_journals_sample/341-Article Text-881-1-10-20170922_1.pdf\n",
      "/data/users/brandon/ob1-projects/data_processing/indo_journals_sample/6320-15524-1-PB.pdf\n",
      "/data/users/brandon/ob1-projects/data_processing/indo_journals_sample/5739-20410-1-PB_1.pdf\n",
      "/data/users/brandon/ob1-projects/data_processing/indo_journals_sample/38468-140984-2-PB_2.pdf\n",
      "/data/users/brandon/ob1-projects/data_processing/indo_journals_sample/35260-83175-1-PB_1.pdf\n",
      "/data/users/brandon/ob1-projects/data_processing/indo_journals_sample/3710-12729-1-PB.pdf\n",
      "/data/users/brandon/ob1-projects/data_processing/indo_journals_sample/1132-2533-1-PB.pdf\n",
      "/data/users/brandon/ob1-projects/data_processing/indo_journals_sample/5708-20097-2-PB.pdf\n",
      "/data/users/brandon/ob1-projects/data_processing/indo_journals_sample/685-1497-2-PB.pdf\n",
      "/data/users/brandon/ob1-projects/data_processing/indo_journals_sample/22262-74010-2-PB.pdf\n",
      "/data/users/brandon/ob1-projects/data_processing/indo_journals_sample/6372-Article Text-12923-1-10-20150727.pdf\n",
      "/data/users/brandon/ob1-projects/data_processing/indo_journals_sample/56462-128032-1-SM.pdf\n",
      "/data/users/brandon/ob1-projects/data_processing/indo_journals_sample/59022-133626-4-PB.pdf\n",
      "/data/users/brandon/ob1-projects/data_processing/indo_journals_sample/4509-12425-1-PB_4.pdf\n",
      "/data/users/brandon/ob1-projects/data_processing/indo_journals_sample/5325-15686-2-PB_1.pdf\n",
      "/data/users/brandon/ob1-projects/data_processing/indo_journals_sample/11317-Article Text-22730-1-10-20160701_1.pdf\n",
      "/data/users/brandon/ob1-projects/data_processing/indo_journals_sample/4606-11499-1-PB.pdf\n",
      "/data/users/brandon/ob1-projects/data_processing/indo_journals_sample/13513-29520-1-SM_1.pdf\n",
      "/data/users/brandon/ob1-projects/data_processing/indo_journals_sample/648-1168-1-SM_1.pdf\n",
      "/data/users/brandon/ob1-projects/data_processing/indo_journals_sample/46725-Article Text-132878-1-10-20210701_5.pdf\n",
      "/data/users/brandon/ob1-projects/data_processing/indo_journals_sample/21859-48613-1-SM_2.pdf\n",
      "/data/users/brandon/ob1-projects/data_processing/indo_journals_sample/7180-15677-1-PB_5.pdf\n",
      "/data/users/brandon/ob1-projects/data_processing/indo_journals_sample/4132-11245-1-PB.pdf\n",
      "/data/users/brandon/ob1-projects/data_processing/indo_journals_sample/626-1375-1-SM.pdf\n"
     ]
    }
   ],
   "source": [
    "# print all pdf_path values\n",
    "for pdf_path in df[\"pdf_path\"].unique():\n",
    "    file_path = os.path.join(\"/data/users/brandon/ob1-projects/data_processing/indo_journals_sample\", pdf_path.split(\"/\")[-1])\n",
    "    print(file_path)\n",
    "\n",
    "# bytes\n",
    "# with open(file_path, \"rb\") as f:\n",
    "#     print(f.read())\n",
    "\n",
    "# print(df.iloc[1][\"ocr_text\"])\n",
    "# print(df.iloc[1][\"is_relevant\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No matching PDF path found in the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "# Filter the DataFrame\n",
    "filtered_df = df[df[\"pdf_path\"] == \"/data/users/brandon/ob1-projects/data_processing/indo_journals_sample/vgabler%2C+fulltext.pdf_;filename_=UTF-8''vgabler%2C+fulltext_3852.pdf\"]\n",
    "\n",
    "# Check if the filtered DataFrame is not empty before accessing values\n",
    "if not filtered_df.empty:\n",
    "    print(filtered_df[\"ocr_text\"].values[0])\n",
    "else:\n",
    "    print(\"No matching PDF path found in the DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You are an expert Language Identification Detector. Your task is to determine if the primary content of a research paper is in Indonesian based on its OCR output. This task is crucial for training a Large Language Model to improve its Indonesian language performance.\n",
    "\n",
    "Here is the OCR output of the research paper:\n",
    "\n",
    "<ocr_output>\n",
    "{{OCR_OUTPUT}}\n",
    "</ocr_output>\n",
    "\n",
    "Carefully analyze the OCR output and determine if the primary content is in Indonesian. Consider the following guidelines:\n",
    "\n",
    "1. The majority of the text should be in Indonesian.\n",
    "2. Technical terms, citations, or references in English are acceptable as long as they don't make up a significant portion of the content.\n",
    "3. If the paper contains substantial sections in English (e.g., abstract, conclusion, or entire paragraphs) that are difficult to remove via REGEX scripts, consider the paper inappropriate for training the Indonesian LLM.\n",
    "4. Be aware that OCR errors might affect some words, but focus on the overall language pattern.\n",
    "\n",
    "If you encounter any English content that is more than just scattered words or phrases, and would be difficult to remove with simple REGEX scripts, consider the paper unsuitable for training the Indonesian LLM.\n",
    "\n",
    "Provide your analysis and reasoning in the \"reasoning\" key of the JSON output. Then, based on your analysis, determine whether the paper is suitable (True) or unsuitable (False) for training the Indonesian LLM, and include this in the \"answer\" key of the JSON output.\n",
    "\n",
    "Your output should be in the following JSON format:\n",
    "\n",
    "<output>\n",
    "{\n",
    "  \"reasoning\": \"Your detailed analysis and reasoning here\",\n",
    "  \"answer\": true/false\n",
    "}\n",
    "</output>\n",
    "\n",
    "Remember to provide your reasoning before giving the final answer. Ensure your reasoning is thorough and supports your conclusion.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "\n",
    "client = anthropic.Anthropic(\n",
    "    # defaults to os.environ.get(\"ANTHROPIC_API_KEY\")\n",
    "    api_key=\"my_api_key\",\n",
    ")\n",
    "\n",
    "# Replace placeholders like {{OCR_OUTPUT}} with real values,\n",
    "# because the SDK does not support variables.\n",
    "message = client.messages.create(\n",
    "    model=\"claude-3-5-sonnet-20240620\",\n",
    "    max_tokens=1000,\n",
    "    temperature=0,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"You are an expert Language Identification Detector. Your task is to determine if the primary content of a research paper is in Indonesian based on its OCR output. This task is crucial for training a Large Language Model to improve its Indonesian language performance.\\n\\nHere is the OCR output of the research paper:\\n\\n<ocr_output>\\n{{OCR_OUTPUT}}\\n</ocr_output>\\n\\nCarefully analyze the OCR output and determine if the primary content is in Indonesian. Consider the following guidelines:\\n\\n1. The majority of the text should be in Indonesian.\\n2. Technical terms, citations, or references in English are acceptable as long as they don't make up a significant portion of the content.\\n3. If the paper contains substantial sections in English (e.g., abstract, conclusion, or entire paragraphs) that are difficult to remove via REGEX scripts, consider the paper inappropriate for training the Indonesian LLM.\\n4. Be aware that OCR errors might affect some words, but focus on the overall language pattern.\\n\\nIf you encounter any English content that is more than just scattered words or phrases, and would be difficult to remove with simple REGEX scripts, consider the paper unsuitable for training the Indonesian LLM.\\n\\nProvide your analysis and reasoning in the \\\"reasoning\\\" key of the JSON output. Then, based on your analysis, determine whether the paper is suitable (True) or unsuitable (False) for training the Indonesian LLM, and include this in the \\\"answer\\\" key of the JSON output.\\n\\nYour output should be in the following JSON format:\\n\\n<output>\\n{\\n  \\\"reasoning\\\": \\\"Your detailed analysis and reasoning here\\\",\\n  \\\"answer\\\": true/false\\n}\\n</output>\\n\\nRemember to provide your reasoning before giving the final answer. Ensure your reasoning is thorough and supports your conclusion.\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "print(message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "indo_journal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
