{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 25 PDF files and copied them to /data/users/brandon/ob1-projects/data_processing/indo_journals_sample\n"
     ]
    }
   ],
   "source": [
    "# randomy copy 500 pdfs from indo_journals to indo_journals_sample folder\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Define the source and destination directories\n",
    "source_dir = \"/data/users/brandon/ob1-projects/data_processing/indo_journals\"\n",
    "destination_dir = \"/data/users/brandon/ob1-projects/data_processing/indo_journals_sample\"\n",
    "\n",
    "# Create the destination directory if it doesn't exist\n",
    "os.makedirs(destination_dir, exist_ok=True)\n",
    "\n",
    "# Get a list of all PDF files in the source directory\n",
    "pdf_files = [f for f in os.listdir(source_dir) if f.endswith('.pdf')]\n",
    "\n",
    "# Randomly select 500 PDF files\n",
    "selected_pdfs = random.sample(pdf_files, 25)\n",
    "\n",
    "# Copy the selected PDF files to the destination directory\n",
    "for pdf in selected_pdfs:\n",
    "    shutil.copy(os.path.join(source_dir, pdf), os.path.join(destination_dir, pdf))\n",
    "\n",
    "print(f\"Selected {len(selected_pdfs)} PDF files and copied them to {destination_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            pdf_path  \\\n",
      "0  /home/ubuntu/Indo-Journals/indo_journals_subse...   \n",
      "1  /home/ubuntu/Indo-Journals/indo_journals_subse...   \n",
      "2  /home/ubuntu/Indo-Journals/indo_journals_subse...   \n",
      "3  /home/ubuntu/Indo-Journals/indo_journals_subse...   \n",
      "4  /home/ubuntu/Indo-Journals/indo_journals_subse...   \n",
      "\n",
      "                           extracted_meaningful_text  \n",
      "0  CiE 10 ! in Terakreditasi SINTA 5 http://journ...  \n",
      "1  ISSN : 2654-8305 ISSN : 2654-8313 Vol 1 , Nove...  \n",
      "2  Edu Elektrika 5 ! # Edu Elektrika Journal http...  \n",
      "3  Edu Komputika 9 ! # Edu Komputika Journal ! ht...  \n",
      "4  Memilih Lokasi Untuk Bangunan Pada Lereng Perb...  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6427 entries, 0 to 6426\n",
      "Data columns (total 2 columns):\n",
      " #   Column                     Non-Null Count  Dtype \n",
      "---  ------                     --------------  ----- \n",
      " 0   pdf_path                   6427 non-null   object\n",
      " 1   extracted_meaningful_text  6427 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 100.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "# df = pd.read_csv(\"/data/users/brandon/ob1-projects/data_processing/ocr_results.csv\")\n",
    "# df = pd.read_csv(\"/data/users/brandon/ob1-projects/data_processing/subset_5_filtered.csv\")\n",
    "# df = pd.read_csv(\"/data/users/brandon/ob1-projects/data_processing/sample_filtered.csv\")\n",
    "df = pd.read_csv(\"/data/users/brandon/ob1-projects/data_processing/subset_1_final_output.csv\")\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Display information about the DataFrame\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4029    Error: Failed to process PDF /home/ubuntu/Indo...\n",
      "5466    Error: Failed to process PDF /home/ubuntu/Indo...\n",
      "185     Error: Failed to process PDF /home/ubuntu/Indo...\n",
      "2847    Error: Failed to process PDF /home/ubuntu/Indo...\n",
      "3674    Error: Failed to process PDF /home/ubuntu/Indo...\n",
      "6201    Edu Komputika 8 ! Edu Komputika Journal http:/...\n",
      "2552    Error: Failed to process PDF /home/ubuntu/Indo...\n",
      "6053    Error: Failed to process PDF /home/ubuntu/Indo...\n",
      "3535                       Error: Failed to process PDF 5\n",
      "1155    Error: Failed to process PDF /home/ubuntu/Indo...\n",
      "Name: extracted_meaningful_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# find rows where extracted_meaningful_text contains string Error\n",
    "df_errors = df[df[\"extracted_meaningful_text\"].str.contains(\"Error\")]\n",
    "\n",
    "print(df_errors[\"extracted_meaningful_text\"].sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_errors[df_errors[\"extracted_meaningful_text\"].str.contains(\"Error: Failed to process PDF /home/ubuntu\")]\n",
    "\n",
    "# find errors where extracted_meaningful_text contains string Error but not Failed to process PDF   \n",
    "non_pdf_errors = df_errors[~df_errors[\"extracted_meaningful_text\"].str.contains(\"Error: Failed to process PDF /home/ubuntu\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               pdf_path  \\\n",
      "13                                                study   \n",
      "61                                              Rahmini   \n",
      "134                             ted by the order from 4   \n",
      "143                                Beekeeping or fo lds   \n",
      "149    Gambar 2. Korelogram ACF dan PACF kasus hiper...   \n",
      "...                                                 ...   \n",
      "6295                                       Non PNS 7 38   \n",
      "6298                                        Buruk 13 12   \n",
      "6312                                   Kg and woman  66   \n",
      "6358                                    Jurnal Pandecta   \n",
      "6365                                       CTPS per RW    \n",
      "\n",
      "                              extracted_meaningful_text  \n",
      "13                   Error: Failed to process PDF study  \n",
      "61                 Error: Failed to process PDF Rahmini  \n",
      "134   Error: Failed to process PDF ted by the order ...  \n",
      "143   Error: Failed to process PDF Beekeeping or fo lds  \n",
      "149                        Error: Failed to process PDF  \n",
      "...                                                 ...  \n",
      "6295          Error: Failed to process PDF Non PNS 7 38  \n",
      "6298           Error: Failed to process PDF Buruk 13 12  \n",
      "6312       Error: Failed to process PDF Kg and woman 66  \n",
      "6358       Error: Failed to process PDF Jurnal Pandecta  \n",
      "6365           Error: Failed to process PDF CTPS per RW  \n",
      "\n",
      "[391 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "bad_pdf_path_df =non_pdf_errors[~non_pdf_errors[\"pdf_path\"].str.contains(\"/home/ubuntu\")]\n",
    "# print all rows\n",
    "print(bad_pdf_path_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print sample for extracted_meaningful_text\n",
    "# print(df[\"extracted_meaningful_text\"][5])\n",
    "\n",
    "# load /data/users/brandon/ob1-projects/data_processing/sample_filtered_5_true.csv\n",
    "df_sample_5 = pd.read_csv(\"/data/users/brandon/ob1-projects/data_processing/sample_5_final_output.csv\")\n",
    "\n",
    "# extract only pdf path and extracted_meaningful_text\n",
    "df_sample_5 = df_sample_5[[\"pdf_path\", \"extracted_meaningful_text\"]]\n",
    "\n",
    "# save to csv\n",
    "df_sample_5.to_csv(\"/data/users/brandon/ob1-projects/data_processing/sample_5_final_output_2.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'is_relevant'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/indo_journal/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'is_relevant'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# statistics for is_relevant\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mis_relevant\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalue_counts())\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# sample 20 rows where is_relevant is False\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# df_true = df[df[\"is_relevant\"] == True].sample(5)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# for pdf_path in df_false[\"pdf_path\"].unique():\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#     file_path = os.path.join(\"/data/users/brandon/ob1-projects/data_processing/indo_journals_subsets/subset_5\", pdf_path.split(\"/\")[-1])\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#     print(file_path)\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/indo_journal/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.conda/envs/indo_journal/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'is_relevant'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# statistics for is_relevant\n",
    "print(df[\"is_relevant\"].value_counts())\n",
    "# sample 20 rows where is_relevant is False\n",
    "# df_true = df[df[\"is_relevant\"] == True].sample(5)\n",
    "\n",
    "# for pdf_path in df_false[\"pdf_path\"].unique():\n",
    "#     file_path = os.path.join(\"/data/users/brandon/ob1-projects/data_processing/indo_journals_subsets/subset_5\", pdf_path.split(\"/\")[-1])\n",
    "#     print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "# save df_false to csv\n",
    "df_true.to_csv(\"/data/users/brandon/ob1-projects/data_processing/sample_filtered_5_true.csv\", index=False)\n",
    "print(len(df_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "print(len(df[\"pdf_path\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/users/brandon/ob1-projects/data_processing/indo_journals_sample/7713-30855-1-PB.pdf\n",
      "/data/users/brandon/ob1-projects/data_processing/indo_journals_sample/1346-2801-1-PB_1.pdf\n",
      "/data/users/brandon/ob1-projects/data_processing/indo_journals_sample/6468-22979-1-PB.pdf\n",
      "/data/users/brandon/ob1-projects/data_processing/indo_journals_sample/230-Article Text-696-2-10-20191220_1.pdf\n",
      "/data/users/brandon/ob1-projects/data_processing/indo_journals_sample/25429-Article Text-80771-1-10-20190518.pdf\n",
      "/data/users/brandon/ob1-projects/data_processing/indo_journals_sample/10.+2584+231-240.pdf_;filename_=UTF-8''10.+2584+231-240_1.pdf\n",
      "/data/users/brandon/ob1-projects/data_processing/indo_journals_sample/34745-78810-2-PB.pdf\n",
      "/data/users/brandon/ob1-projects/data_processing/indo_journals_sample/11194-40347-2-PB_1.pdf\n",
      "/data/users/brandon/ob1-projects/data_processing/indo_journals_sample/7278-14695-2-PB_3.pdf\n",
      "/data/users/brandon/ob1-projects/data_processing/indo_journals_sample/41145-177007-1-PB.pdf\n",
      "/data/users/brandon/ob1-projects/data_processing/indo_journals_sample/6337-Article Text-36981-1-10-20220627.pdf\n",
      "/data/users/brandon/ob1-projects/data_processing/indo_journals_sample/21170-Article Text-79968-1-10-20190430_1.pdf\n",
      "/data/users/brandon/ob1-projects/data_processing/indo_journals_sample/36251-136227-1-PB_1.pdf\n",
      "/data/users/brandon/ob1-projects/data_processing/indo_journals_sample/6922-Article Text-25443-2-10-20210919_1.pdf\n",
      "/data/users/brandon/ob1-projects/data_processing/indo_journals_sample/784-1363-1-PB.pdf\n",
      "/data/users/brandon/ob1-projects/data_processing/indo_journals_sample/22690-55430-1-SM_2.pdf\n",
      "/data/users/brandon/ob1-projects/data_processing/indo_journals_sample/776-1446-1-SM_1.pdf\n",
      "/data/users/brandon/ob1-projects/data_processing/indo_journals_sample/10664-39765-6-PB_1.pdf\n",
      "/data/users/brandon/ob1-projects/data_processing/indo_journals_sample/3254-10041-1-PB_1.pdf\n",
      "/data/users/brandon/ob1-projects/data_processing/indo_journals_sample/1577-3229-1-SM.pdf\n",
      "/data/users/brandon/ob1-projects/data_processing/indo_journals_sample/2141-4238-1-SM.pdf\n",
      "/data/users/brandon/ob1-projects/data_processing/indo_journals_sample/64815-Article Text-201007-1-10-20230516_1.pdf\n",
      "/data/users/brandon/ob1-projects/data_processing/indo_journals_sample/1004-3591-1-PB_1.pdf\n",
      "STRATEGI MANAJEMEN SEBAGAI FAKTOR MITICASI DALAM\n",
      "PENERIMAAN OPINI AUDIT\n",
      "StudiEmpirik pada P.rusahsan M!truftktur di Indonesi.\n",
      "h41rtu4t of ke rtphcss q k? ten. ol ttr q@s! lt stdes 4 rtrtsctiar Jodo D\n",
      "FedtakB the qcepbrc. olcco th Dvha JtErckt b&a lnrts 'lth r: :ate alcan on aott\n",
      "fheA 1 shov thd the slk {.@ an !a.t tunt.E! ond Bvon@ alEt a. tt4t'dutu rld t\n",
      "*aks arc thc itt|atrr?dqs k odtt t olqahe orcqn qhi@ |\n",
      "1,d1 nlt ldar d ircdce th! t&\n",
      "a d(P^edlod a$d 'rcbs\n",
      "rcqtNe okoh| earqd oPktrn\n",
      "K4\\q^:xohlb unqubn ltwuqqtind, aEsDd mdeN hnedon kdq.\n",
      "m[,o( aloi il6hl d pogghi La;\n",
      "r€uesn m4FlJi E mbtrm4 D; ioreNum b.r;e$;rlt! rqsql PeneFic etrs0 hi i_lalneilditrNd\n",
      "pcrurhln mrr, m.aniuLt kh;s\n",
      "blhdh3J{eix.lh?o,.[,Jd;,i\n",
      "p.me!.4 alsn dfi phgg0a heo;\n",
      "r$!hrr3r erm Fmbhh 6 ne(Mudrh, 03r, opi, s4aP o/.; kism{he||'d },;\n",
      "lm! hdLnl,L;^\n",
      "dfhbl liEn;\n",
      "okh ebdb tr nrtenq 4 ed;ri\n",
      "J , opn \\di!r ,iooiptn3ellrdliJbddPsfh.oon\n",
      "Rrhsdi;! J\n",
      "$h,j,hF, nauens krusri\n",
      "@;, s\" ,_-\n",
      "rertmi d,n &L,f eir - ir dEL}lnmgl nd, J qmfJ! @n'!/;.al!rt|J ! J trbU tb]s hko n[o;t!, r',t.*\" \"c. e.\"s -,;- fuol m cr- mefu!in luod.i 1n\n",
      "kdid.kp*i- ,\"hhgs\" d.e\" .:*r;,\n",
      "(Md.hrer,r93r;re35i!e36i Murljlq dmlupuimempfttpJperu*han64init,E^Et\"'* \"^ *tI tufiUh\" _; ._rMu.rrk( rosc:Hor$mdH! , teie)\n",
      "FE h\"., ;b-r..,,p,- \"u- ,\"*, a\"t\",i\n",
      "1f,4n3 @,csr,, heqtjnskxn judilor udnc c'rtr,t rc !E m ,kms hrr\n",
      "\",r au*- ira\n",
      ".d - *\". .;.*$d;,r r\"!,,\n",
      "l.]Ei.nck6dd]&5'didlk[r\n",
      "a\"',9- trt^u' **.gI t,l\"* ut,l.tliFruahi, hos rm l4( a/ rtr,sr , tJ,\n",
      ".o,r, r- \"\"\".,;, gr. e-a.r..,i_Ftrk Fnl.,: Ltsd( Drl)r .-\" i;,n, n,i!rrr r nnid **.h-; ;_,1,dii rindrkd shkjik yiis di|J drikLrln\n",
      "fulLfiE'h-,1.'molrdr d 'd\"r mdL,Ld \"--.. \"; b\",. rsa uo, Bd, \" d)!!l\n",
      "trml rrjr rqhr Ftr3li;r !Edll b'! kf,i ui\n",
      "p*l* am a,tt,,l\", pa. p*.+..i..1\n",
      ", tl *,lul.i\n",
      "tirdtid distlr dier ms;nnsjkm]g(im pdEi.m| oojl o,;.^\". Ja d,pJ d |.\" h, g ' b r L[.;\n",
      "n^'Lrk rur fi^!r (.irnj eso,\n",
      "MA*,MUM vo 4'No,'M:.t,0,.4 A€,*',onE\n",
      "kem npuin pero$hen md jurkm\n",
      "nmbnik opiri 3,,,s o,-r, {Biur-Btl'\n",
      ". Hublnsa! skrtsr Mdijtrrl Arr\n",
      "M rjlma' p.rru nd*dh nmrei\n",
      "k.@'B' +m mmjRg. keberr ssnsnuil[(ldrd'driSnit[, 934)\n",
      "n iiem( idirirr\n",
      "Fnd:paar p.i'juara' rki'! ap diglmk.n\n",
      "snd $mm d Lri (200r) ras\n",
      "rco&hni bidniltratrtor 'irr51 P1\n",
      "sAS re ( esr) &o PsA r0 (sPAP,200r)\n",
      "mnajcdar wr\n",
      "nqrjud rllila ridak Ndul,i. brg\n",
      "Fru*rr:i rig mordinL lerrl,ttr6r r s sdij!h)_. dip.nirib 3krtr\n",
      "srr,'r-qi ff'turr ikrih 'idar pftd'klif\n",
      "Aiaodurjri (ree6)\n",
      ".upikm liib,/io\n",
      "flr, e kgindijr, sd ndlr rdd.if\n",
      "Kor! lrE!/ ,/i,br |Frffo,-!\n",
      "n rF rn!( nNikuk \"nei gupcruihen Mrrblg d d (rer7)\n",
      "meuijlkkai d E b.dibiiirs nmii.ms\n",
      "D,ol[nn prla sAS 5e( e33) dsptri\n",
      "PsA r0 (SPAP,200l) o.hiin audilor rnuk\n",
      "mrnjcns uur\n",
      "msgrlu .n slram baru, khDsir-i brsi\n",
      "ossdimi ,noiuaT\n",
      "rmks, FB msunLkle ssd4i @rk\n",
      "msias k{rmgsntr3 rridu! P. sh.r'\n",
      "(Lisalle drr An.ndidie,re%)\n",
      "n rgika.bs dekl rdaijunrlM! o'kLp\n",
      "oriii sohs r\",-r, (B ym*h de\n",
      "Ro$ (le??) bdi*r pcnr.lD lsg\n",
      "d d lree?) hilnu ps{,h.oi,'jotrr' dflr\n",
      "Edm d 1 (:00r)\n",
      "NirLek 5(:006)Iang\n",
      "rem n msJi.mtil\n",
      "mlnghindi.i p{ in*n opiii s,/,r .,,@.,\n",
      "kha Jmrcg ii m€[!fut.tr 5ahi !;\n",
      "bidni twrbt d6n{! \\Pare ti a d\n",
      ".-],?d,,]\"',\",\".\n",
      "\"hu d.n$tr '.a;\n",
      "p.{!ara kepd p.DBen }4 n4rb*i\n",
      "(sPAr.?ooi nlnbo letuorul h(inrc.m mrioem€i\n",
      "pmi.L$i rpotu\n",
      "p smne Lraj\" hnor ;4\n",
      ":,il:iil::;::r\" ' *'' ***\". '\"\"\n",
      "msuPrkf hkbr nirkd di;I.nrlh,gn uPhi !a,4.,tr(;':.s. Hrrungsn dmrs, Lcrtrr0, d,ubhkll tJiali n ,,ig d.iM oiin\n",
      "sr esi k.rj,sna yor dirakurom ajehe' h{qarshanij.i{ d?r,m up.y, urtuk m.mfd;\n",
      "durunsai $'E k*sjnanbuma di; hf\"mha bi I f\"ib! . Fiiua ; Duo hrrmhruru;r mha\n",
      "rmrd rtr'lri Fiiuq ?b.ji bdii &ildagicrmdfur\"dlHof.l.B!a\\D.n,r r 11( u r rnt,\n",
      "&l b(ur ,;\"rzuq ,i!rr nnbcis.kuihs dxn aiid\n",
      "brhv, f rli ko mr / kfs D i qdl!k''|,tr de|gJtr Dl,, Eruj]u -dh;\n",
      "drF, m.'n rrr rii.l; Y!iDii.f:L.bm rsnju'. M(he d4 shArr ueebr\n",
      "nqngl m linskl funi!a] o[h6;s\n",
      "e<mrrLrsnFmrhtr ier..b\n",
      "ndakuke ke !;imrudm s;,3,u\n",
      "ore,r5a' oLrr lls. r Lflrk ad,;,nsgnd\"p e.ruar*n y4g $drE\n",
      "dirsr {brt,nn.ribunLsdrh@n;tr*r t6n ABndelr ren\n",
      "fudiumvsPrcl.idrar od bskBE r;b; ;r-D^\n",
      ",,tuk /uAdar dt.i hsir dr; d!*\n",
      "w *.rqs.2006) \n",
      "^prbih eoEli €r&I.-e\",; r* h\"\n",
      "menuodr uitok membriklr oPini ,orr\n",
      "rotr, n I FnrL p,q\";s !_^..si,4l hrn aL m, mn..h,;.\n",
      ",.6. H6;sn n*tr4 n.dur rcE ,\n",
      "I!ahrdtr +rq r-sr, p,,,j-6 r;e\n",
      "u., ,*,rL.il..\"tu rdJ d- mt,i,+dr k;_._*,r Mr\"rli.o\n",
      "e..\" \",1 t,oottut-, +.\"m\"; ', r\n",
      "|',,\"9. ,--\".d q|.*4 \\;q\n",
      "n,s . p. \n",
      "' -srp\"d, \"o \"s pe;?s b a_\n",
      ",-,{\"' d.,r F\"c\",$-c; md,k s,ii\n",
      "sruan disribEi ydg $d,h b.ilran\n",
      "&drgi p.ic.frbanga prcduk juga srrir\n",
      "dikrrtutr de.g.n mha m€mFa4jats dlu\n",
      "sdeeiy,igdlpaldip.nimb?iekano.h\n",
      "n.nrj.d.i uiok ntrjrga k€l.l'glmg\n",
      "merbq k opioi(B Yis€ls dii wiLlekeN.2006)\n",
      "k rmpui psNhon Dru( rddjulk\n",
      "sah F d,Pa' dilrnjukli,' detrgRitirdiiya kegigaLitr keu gln lrnoa,,rd,rkd Kond' ks.igrn dilslukk.tr\n",
      "oryrtihq rratu h lth B.nr 4,t eaat)dm Boytr*ls d Nill{L.is (20116).\n",
      "Dnni hio ErjadirF hlgiga e\n",
      "hdrns I d.6! ,e6l baili J-sng riibuL k?rm\n",
      "kexijibam)i asu\n",
      "memeDhiFrja'rrEn hlrns ns4rki shi\n",
      "3'4 @4@ bx-!i\n",
      "Fru$[mn yaas ]!bih k-i (Mm.h 0s6)\n",
      "irE^i nfrrrki sn nrrnndr ! qbisa po6ya udui mchbdikd kJcdil kepadi\n",
      "3or€ @rcqn Lebil' rmjul dap ditekskf\n",
      "m€ngakibd\\ai jaiuhiya perushdi n!4'\n",
      "rltllud pnpheq, 4led lMrttitt te31)\n",
      "n$d.Glsi $krr sji, ke nig.tr, du\n",
      "(rs?)id.n,khbulri bdr*.ludior3,s6\n",
      "/r.,0ol /^?4J . Lebih Li't'tr, o.iler d.n\n",
      "RashuroDd (100)\n",
      "Bre Ei* r\"don. ! (BED do,sn masu\n",
      "DnIho, uc D)\n",
      "mmufiku y!o! r^ri( di Br$ ralk\n",
      "hdoisia lBEr) d:ri\n",
      "Mhur 1010 sjumhh xe rerua u\n",
      "se renh! $n\n",
      "sbrei b{ik 10It!6^gri yftg lmglip, (b) h.Erb \n",
      "'kxtr\n",
      "G) msg, ori o6r:hl orEr rt,.ir\n",
      "30/ts 1!^4? (ccol!rlr oD \\Er,1u!! D{lcarni (Ll\n",
      "4rri,l )rg drd [ii. 'i i]l Lln.bL'\n",
      "5n'+ il k LlL,d Ld]r U liisI\"*, tu,.. G- Ba, s..qt\n",
      "srEreiPo*e$uje Produk Bn j s;d .\n",
      "i,qrrgundiir tLt kLridik. duku d-4i\n",
      "s o rkr r Lur dbsr rrhDq lim, i:l\n",
      "j!\" r1 \" Lq bk a(uJ rlmlLlb 5d U deE,n m'pr irq;mmujukr,j jdrsrik\n",
      "bgisltl \n",
      "^'l:I fue] reg6l lo3islll ;tr\n",
      "d ijnkii rlrir od! oarrililn:i.oga sri! rhni ilhe i1\n",
      "i(d0rn!) uldur r, r(dunrrl\n",
      "Poieji) lripd-n d:hfr Fn,,ni\n",
      "dik, bs(rk u n]rtuLtr;rd h ,ihqru! kro rokLxii liir em k.r r;j\n",
      "0e ru\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# print all pdf_path values\n",
    "for pdf_path in df[\"pdf_path\"].unique():\n",
    "    file_path = os.path.join(\"/data/users/brandon/ob1-projects/data_processing/indo_journals_sample\", pdf_path.split(\"/\")[-1])\n",
    "    print(file_path)\n",
    "\n",
    "# bytes\n",
    "# with open(file_path, \"rb\") as f:\n",
    "#     print(f.read())\n",
    "\n",
    "print(df.iloc[1][\"ocr_text\"][:6000])\n",
    "# print(df.iloc[1][\"is_relevant\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No matching PDF path found in the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "# Filter the DataFrame\n",
    "filtered_df = df[df[\"pdf_path\"] == \"/data/users/brandon/ob1-projects/data_processing/indo_journals_sample/vgabler%2C+fulltext.pdf_;filename_=UTF-8''vgabler%2C+fulltext_3852.pdf\"]\n",
    "\n",
    "# Check if the filtered DataFrame is not empty before accessing values\n",
    "if not filtered_df.empty:\n",
    "    print(filtered_df[\"ocr_text\"].values[0])\n",
    "else:\n",
    "    print(\"No matching PDF path found in the DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You are an expert Language Identification Detector. Your task is to determine if the primary content of a research paper is in Indonesian based on its OCR output. This task is crucial for training a Large Language Model to improve its Indonesian language performance.\n",
    "\n",
    "Here is the OCR output of the research paper:\n",
    "\n",
    "<ocr_output>\n",
    "{{OCR_OUTPUT}}\n",
    "</ocr_output>\n",
    "\n",
    "Carefully analyze the OCR output and determine if the primary content is in Indonesian. Consider the following guidelines:\n",
    "\n",
    "1. The majority of the text should be in Indonesian.\n",
    "2. Technical terms, citations, or references in English are acceptable as long as they don't make up a significant portion of the content.\n",
    "3. If the paper contains substantial sections in English (e.g., abstract, conclusion, or entire paragraphs) that are difficult to remove via REGEX scripts, consider the paper inappropriate for training the Indonesian LLM.\n",
    "4. Be aware that OCR errors might affect some words, but focus on the overall language pattern.\n",
    "\n",
    "If you encounter any English content that is more than just scattered words or phrases, and would be difficult to remove with simple REGEX scripts, consider the paper unsuitable for training the Indonesian LLM.\n",
    "\n",
    "Provide your analysis and reasoning in the \"reasoning\" key of the JSON output. Then, based on your analysis, determine whether the paper is suitable (True) or unsuitable (False) for training the Indonesian LLM, and include this in the \"answer\" key of the JSON output.\n",
    "\n",
    "Your output should be in the following JSON format:\n",
    "\n",
    "<output>\n",
    "{\n",
    "  \"reasoning\": \"Your detailed analysis and reasoning here\",\n",
    "  \"answer\": true/false\n",
    "}\n",
    "</output>\n",
    "\n",
    "Remember to provide your reasoning before giving the final answer. Ensure your reasoning is thorough and supports your conclusion.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "\n",
    "client = anthropic.Anthropic(\n",
    "    # defaults to os.environ.get(\"ANTHROPIC_API_KEY\")\n",
    "    api_key=\"my_api_key\",\n",
    ")\n",
    "\n",
    "# Replace placeholders like {{OCR_OUTPUT}} with real values,\n",
    "# because the SDK does not support variables.\n",
    "message = client.messages.create(\n",
    "    model=\"claude-3-5-sonnet-20240620\",\n",
    "    max_tokens=1000,\n",
    "    temperature=0,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"You are an expert Language Identification Detector. Your task is to determine if the primary content of a research paper is in Indonesian based on its OCR output. This task is crucial for training a Large Language Model to improve its Indonesian language performance.\\n\\nHere is the OCR output of the research paper:\\n\\n<ocr_output>\\n{{OCR_OUTPUT}}\\n</ocr_output>\\n\\nCarefully analyze the OCR output and determine if the primary content is in Indonesian. Consider the following guidelines:\\n\\n1. The majority of the text should be in Indonesian.\\n2. Technical terms, citations, or references in English are acceptable as long as they don't make up a significant portion of the content.\\n3. If the paper contains substantial sections in English (e.g., abstract, conclusion, or entire paragraphs) that are difficult to remove via REGEX scripts, consider the paper inappropriate for training the Indonesian LLM.\\n4. Be aware that OCR errors might affect some words, but focus on the overall language pattern.\\n\\nIf you encounter any English content that is more than just scattered words or phrases, and would be difficult to remove with simple REGEX scripts, consider the paper unsuitable for training the Indonesian LLM.\\n\\nProvide your analysis and reasoning in the \\\"reasoning\\\" key of the JSON output. Then, based on your analysis, determine whether the paper is suitable (True) or unsuitable (False) for training the Indonesian LLM, and include this in the \\\"answer\\\" key of the JSON output.\\n\\nYour output should be in the following JSON format:\\n\\n<output>\\n{\\n  \\\"reasoning\\\": \\\"Your detailed analysis and reasoning here\\\",\\n  \\\"answer\\\": true/false\\n}\\n</output>\\n\\nRemember to provide your reasoning before giving the final answer. Ensure your reasoning is thorough and supports your conclusion.\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "print(message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "indo_journal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
